# ğŸ“Š TradeInsightsAssistant

> **Conversational AI for Options Intelligence**

![Banner](assets/banner.png)

---

## ğŸš€ What is TradeInsightsAssistant?

TradeInsightsAssistant is your options research analyst â€” powered by natural language. It transforms open interest (OI), volatility positioning, and cross-asset flows into precise trading insights using a powerful chat interface backed by LLMs.

Ask it questions like:

* "Where are traders piling on SPY puts this week?"
* "Whatâ€™s the risk/reward on a June QQQ put spread?"
* "Are there unusual builds in NVDA for Fridayâ€™s expiration?"


---

## ğŸ§  Key Capabilities

### ğŸ’¬ Conversational Intelligence

* Ask questions in plain English
* Receive clean, structured responses
* Get Markdown-formatted trade setups

### ğŸ“ˆ Options Market Analysis

* Open Interest clustering (per strike and expiry)
* Call/Put ratio skew detection
* Max Pain and magnet zones
* Position buildup and liquidation tracking


### âš’ï¸ Professional Trade Outputs

* Spreads, hedges, directional trades
* Entry, stop-loss, profit target rules
* Kelly Criterion sizing and confidence score

---

## ğŸ› ï¸ How It Works

1. Launch the CLI: `python main.py`
2. Choose your LLM backend (Bedrock or Claude API)
3. Start chatting:

```txt
ğŸ“Š You: What are key OI levels on TSLA this week?
ğŸ¤– Agent: The 280 and 300 put strikes show growing OI with strong skew. Gamma risk is concentrated near 290.
```

4. Want to save the response? Just say yes â€” it writes to Markdown with a full metadata trail.

---

## ğŸ” Use Cases

* 0DTE and weekly trade planning
* Institutional flow tracking
* Quantified trade generation
* Hedge scenario simulation
* Risk-layered market analysis

---

## âš¡ Example Prompts

```bash
"Analyze SPY open interest for the next 5 days"
"Whatâ€™s the options flow telling us about AAPL?"
"Show me support and resistance levels for TSLA"
"Give me a put hedge strategy for HOOD next month"
```

---


### Run the CLI:

```bash
python main.py
```

Youâ€™ll be guided to choose your LLM provider (AWS Bedrock or Claude API). From there, start chatting.

---

## ğŸ“‚ MCP Server Configuration

Servers are defined in `mcp_servers.json`:

```json
{
  "servers": [
    {
      "name": "openinterest",
      "command": "mcp-openinterest-server",
      "args": []
    },
    {
      "name": "news",
      "command": "mcp-news-server",
      "args": ["--api-key", "your-key"]
    }
  ]
}
```

Add/remove servers as needed â€” the CLI dynamically loads them.

---

## ğŸ§© Architecture

* âœ… CLI-first UX built on `rich`
* âœ… Orchestrator handles multi-turn LLM conversations
* âœ… Dynamic tool invocation from MCP registry
* âœ… Markdown + JSON output for traceability

---

## ğŸ“œ License

[MIT License](LICENSE)

---
